Enter file contents \documentclass[00-GLMregslides.tex]{subfiles}
\begin{document}
%================================================ %
\begin{frame}[fragile]



sf <- function(y) {
  c('Y>=1' = qlogis(mean(y >= 1)),
    'Y>=2' = qlogis(mean(y >= 2)),
    'Y>=3' = qlogis(mean(y >= 3)))
}

(s <- with(dat, summary(as.numeric(apply) ~ pared + public + gpa, fun=sf)))
 
## as.numeric(apply)    N=400
## 
## +-------+-----------+---+----+--------+------+
## |       |           |N  |Y>=1|Y>=2    |Y>=3  |
## +-------+-----------+---+----+--------+------+
## |pared  |No         |337|Inf |-0.37834|-2.441|
## |       |Yes        | 63|Inf | 0.76547|-1.347|
## +-------+-----------+---+----+--------+------+
## |public |No         |343|Inf |-0.20479|-2.345|
## |       |Yes        | 57|Inf |-0.17589|-1.548|
## +-------+-----------+---+----+--------+------+
## |gpa    |[1.90,2.73)|102|Inf |-0.39730|-2.773|
## |       |[2.73,3.00)| 99|Inf |-0.26415|-2.303|
## |       |[3.00,3.28)|100|Inf |-0.20067|-2.091|
## |       |[3.28,4.00]| 99|Inf | 0.06062|-1.804|
## +-------+-----------+---+----+--------+------+
## |Overall|           |400|Inf |-0.20067|-2.197|
## +-------+-----------+---+----+--------+------+
 
The table above displays the (linear) predicted values we would get if we regressed our dependent variable on our predictor variables one at a time, without the parallel slopes assumption. We can evaluate the parallel slopes assumption by running a series of binary logistic regressions with varying cutpoints on the dependent variable and checking the equality of coefficients across cutpoints. We thus relax the parallel slopes assumption to checks its tenability. To accomplish this, we transform the original, ordinal, dependent variable into a new, binary, dependent variable which is equal to zero if the original, ordinal dependent variable (here apply) is less than some value a, and 1 if the ordinal variable is greater than or equal to a (note, this is what the ordinal regression model coefficients represent as well). This is done for k-1 levels of the ordinal variable and is executed by the as.numeric(apply) >= a coding below. The first line of code estimates the effect of pared on choosing "unlikely" applying versus "somewhat likely" or "very likely". The second line of code estimates the effect of pared on choosing "unlikely" or "somewhat likely" applying versus "very likely" applying. Looking at the intercept for this model (-0.3783), we see that it matches the predicted value in the cell for pared equal to "no" in the column for Y>=1, the value below it, for pared equals "yes" is equal to the intercept plus the coefficient for pared (i.e. -0.3783 + 1.1438 = 0.765).



glm(I(as.numeric(apply) >= 2) ~ pared, family="binomial", data = dat)
 
## 
## Call:  glm(formula = I(as.numeric(apply) >= 2) ~ pared, family = "binomial", 
##     data = dat)
## 
## Coefficients:
## (Intercept)        pared  
##      -0.378        1.144  
## 
## Degrees of Freedom: 399 Total (i.e. Null);  398 Residual
## Null Deviance:	    551 
## Residual Deviance: 534 	AIC: 538
 
glm(I(as.numeric(apply) >= 3) ~ pared, family="binomial", data = dat)
 
## 
## Call:  glm(formula = I(as.numeric(apply) >= 3) ~ pared, family = "binomial", 
##     data = dat)
## 
## Coefficients:
## (Intercept)        pared  
##       -2.44         1.09  
## 
## Degrees of Freedom: 399 Total (i.e. Null);  398 Residual
## Null Deviance:	    260 
## Residual Deviance: 252 	AIC: 256
 
We can use the values in this table to help us assess whether the proportional odds assumption is reasonable for our model. (Note, the table is reproduced below, as well as above.) For example, when pared is equal to "no" the difference between the predicted value for apply greater than or equal to two and apply greater than or equal to three is roughly 2 (-0.378 - -2.440 = 2.062). For pared equal to "yes" the difference in predicted values for apply greater than or equal to two and apply greater than or equal to three is also roughly 2 (0.765 - -1.347 = 2.112). This suggests that the parallel slopes assumption is reasonable (these differences are what graph below are plotting). 
\end{document}
